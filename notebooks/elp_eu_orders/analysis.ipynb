{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ELP EU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from nv_forecasting.load_data.elp_eu_orders_daily import ELPEUOrdersDaily\n",
    "\n",
    "from nv_forecasting.style import set_style\n",
    "\n",
    "from nv_forecasting.feature_engineering.add_time_features import add_time_features\n",
    "from nv_forecasting.feature_engineering.add_lags import add_lags\n",
    "\n",
    "from nv_forecasting.plots import plot_train_val, plot_train_val_test, plot_prediction\n",
    "\n",
    "from nv_forecasting.metrics import get_scores, add_scores_to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'y' # Target column name\n",
    "DATETIME_COLUMN_NAME = 'ds'\n",
    "COLUMNS_TO_LAG = [TARGET, 'count_of_orders']\n",
    "COLUMNS_TO_DROP = [TARGET, 'count_of_orders']\n",
    "\n",
    "# Feature engineering\n",
    "LAGS = [182]\n",
    "\n",
    "# Model training\n",
    "N_OUTER_SPLITS = 4\n",
    "N_INNER_SPLITS = 3\n",
    "N_FINAL_SPLITS = 5\n",
    "TEST_SIZE = 182\n",
    "SCORING = 'neg_mean_squared_error'\n",
    "\n",
    "# Style\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = ELPEUOrdersDaily('data\\\\elp_eu_orders_daily.csv')\n",
    "df = data_handler.get_dataframe(agg='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Initial data exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in ['day', 'day_of_week', 'month', 'year']:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "    sns.lineplot(df, x=getattr(df.index, word), y=df[TARGET])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('$', rotation=0, labelpad=16)\n",
    "    ax.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "    plt.title(f'Mean value of sum of orders for each day, aggregated by {word}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_time_features(df)\n",
    "add_lags(df, lags=LAGS, columns=COLUMNS_TO_LAG)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Data split for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=COLUMNS_TO_DROP)\n",
    "y = df[[TARGET]]\n",
    "\n",
    "outer_cv = TimeSeriesSplit(n_splits=N_OUTER_SPLITS, test_size=TEST_SIZE)\n",
    "inner_cv = TimeSeriesSplit(n_splits=N_INNER_SPLITS, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(N_OUTER_SPLITS*N_INNER_SPLITS, 1, figsize=(20, 3*N_OUTER_SPLITS*N_INNER_SPLITS), sharex=True)\n",
    "\n",
    "for outer_fold, (train_and_val_idx, test_idx) in enumerate(outer_cv.split(y)):\n",
    "    train_and_val, test = y.iloc[train_and_val_idx], y.iloc[test_idx]\n",
    "    for inner_fold, (train_idx, val_idx) in enumerate(inner_cv.split(train_and_val)):\n",
    "        train, val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        ax_idx = outer_fold * N_INNER_SPLITS + inner_fold\n",
    "        plot_train_val_test(ax[ax_idx], TARGET, train, val, test, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning (time series nested cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'rmse': [], 'mae': [], 'r2': []}\n",
    "metrics_monthly = {'rmse': [], 'mae': [], 'mape': [], 'r2': []}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500, 1000, 2000],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(N_OUTER_SPLITS, 1, figsize=(20, 4*N_OUTER_SPLITS), sharex=True)\n",
    "fig, axm = plt.subplots(N_OUTER_SPLITS, 1, figsize=(20, 4*N_OUTER_SPLITS), sharex=True)\n",
    "\n",
    "for outer_fold, (train_idx, test_idx) in enumerate(outer_cv.split(y)):\n",
    "    print(f'--- Outer fold {outer_fold+1} ---')\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        param_grid=param_grid,\n",
    "        cv=inner_cv,\n",
    "        scoring=SCORING,\n",
    "        n_jobs=-1,\n",
    "        verbose=3,\n",
    "        error_score='raise'\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train[TARGET])\n",
    "\n",
    "    print('Best parameters:')\n",
    "    for key, value in grid_search.best_params_.items():\n",
    "        print(f'{key}: {value}')\n",
    "    print()\n",
    "\n",
    "    y_pred = pd.DataFrame(grid_search.predict(X_test),\n",
    "                          columns=['y'],\n",
    "                          index=y_test.index)\n",
    "    \n",
    "    scores = get_scores(y_test, y_pred)\n",
    "    add_scores_to_dict(metrics, scores)\n",
    "\n",
    "    plot_prediction(ax[outer_fold], TARGET, y_train, y_test, y_pred, linewidth=0.5)\n",
    "\n",
    "    y_train = y_train.resample('ME').mean()\n",
    "    y_test = y_test.resample('ME').mean()\n",
    "    y_pred = y_pred.resample('ME').mean()\n",
    "\n",
    "    scores = get_scores(y_test, y_pred)\n",
    "    add_scores_to_dict(metrics_monthly, scores)\n",
    "\n",
    "    plot_prediction(axm[outer_fold], TARGET, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_monthly).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Data split for final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cv = TimeSeriesSplit(N_FINAL_SPLITS, test_size=TEST_SIZE)\n",
    "\n",
    "fig, ax = plt.subplots(N_FINAL_SPLITS, 1, figsize=(20, 3*N_FINAL_SPLITS), sharex=True)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(final_cv.split(y)):\n",
    "    train, val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    plot_train_val(ax[fold], TARGET, train, val, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Final model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grid = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=final_cv,\n",
    "    scoring=SCORING,\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "final_grid.fit(X, y[TARGET])\n",
    "\n",
    "print('Best parameters:')\n",
    "for key, value in final_grid.best_params_.items():\n",
    "    print(f'{key}: {value}')\n",
    "\n",
    "prod_model = final_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(prod_model.feature_importances_,\n",
    "                  index=prod_model.feature_names_in_,\n",
    "                  columns=['val']).sort_values(by='val')\n",
    "\n",
    "fi.plot(kind='barh', figsize=(8, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
